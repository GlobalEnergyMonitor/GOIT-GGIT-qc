{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pygsheets\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_directory = '/Users/baird/Dropbox/_google-api/'\n",
    "gc = pygsheets.authorize(client_secret=credentials_directory+'client_secret.json')\n",
    "spreadsheet = gc.open_by_key('1tcS6Wd-Wp-LTDpLzFgJY_RSNDnbyubW3J_9HKIAys4A')\n",
    "\n",
    "#spreadsheet[1] \"Gas Pipelines\" tab is the second index\n",
    "terms_df_orig = spreadsheet.worksheet('title', 'Terminals').get_as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "owners_df = spreadsheet.worksheet('title', 'Terminal operators/owners (1/3)').get_as_df()\n",
    "owners_df = owners_df.loc[owners_df.ComboID!='']\n",
    "#owners_df.replace('',numpy.nan, inplace=True)\n",
    "\n",
    "owner_parent_links_df = spreadsheet.worksheet('title', 'Owner–parent relationships (2/3)').get_as_df()\n",
    "# only keep the owners with a checked relationship\n",
    "owner_parent_links_df = owner_parent_links_df.loc[owner_parent_links_df['Parent–Owner Relationship Checked?']=='yes']\n",
    "\n",
    "parents_df = spreadsheet.worksheet('title', 'Parent metadata (3/3)').get_as_df(start='A2')\n",
    "parents_df = parents_df.loc[parents_df.Parent!='']\n",
    "\n",
    "\n",
    "\n",
    "owners_df.set_index('ComboID', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get owner data\n",
    "# for those with percents, multiply by parent companies\n",
    "\n",
    "# RULE FOR TRACKER: if there's only one parent or one parent company \n",
    "# for an owner, ASSUME IT'S 100%\n",
    "\n",
    "# if more than one owner, or more than one parent company, \n",
    "# don't make any assumptions to format things\n",
    "# but DO assume equal split otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create list of owner and parent column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_pct_col_names = []\n",
    "owner_col_names = []\n",
    "\n",
    "parent_pct_col_names = []\n",
    "parent_col_names = []\n",
    "\n",
    "for num in range(1,10+1):\n",
    "    owner_pct_col = f'Owner{num}%'\n",
    "    owner_pct_col_names.append(owner_pct_col)\n",
    "    \n",
    "    owner_col = f'Owner{num}'\n",
    "    owner_col_names.append(owner_col)\n",
    "    \n",
    "    parent_pct_col = f'Parent{num}%'\n",
    "    parent_pct_col_names.append(parent_pct_col)\n",
    "    \n",
    "    parent_col = f'Parent{num}'\n",
    "    parent_col_names.append(parent_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "owners_df_existing = owners_df.loc[owners_df.Owner1.notna()] #owners_df.dropna(subset=owner_col_names, how='all') # has at least \n",
    "owners_df_existing_nopercs = owners_df_existing.loc[owners_df_existing['Owner1%'].isna()]\n",
    "owners_df_existing_yespercs = owners_df_existing.loc[owners_df_existing['Owner1%'].notna()]\n",
    "\n",
    "owners_df_empty = owners_df.loc[owners_df.Owner1.isna()] # all owners are nan\n",
    "#owners_df[owner_col_names].isnull(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all owner names are in owner column\n",
    "sorted_owners_list = owners_df[owner_col_names].to_numpy().flatten()\n",
    "sorted_owners_list = sorted(numpy.unique(sorted_owners_list[sorted_owners_list!='']))\n",
    "\n",
    "sorted_parents_list = parents_df.Parent.to_numpy().flatten()\n",
    "sorted_parents_list = sorted(numpy.unique(sorted_parents_list[sorted_parents_list!='']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_op_parents_list = owner_parent_links_df[parent_col_names].to_numpy().flatten()\n",
    "sorted_op_parents_list = sorted(numpy.unique(sorted_op_parents_list[sorted_op_parents_list!='']))\n",
    "\n",
    "sorted_op_owners_list = owner_parent_links_df.Owner.to_numpy().flatten()\n",
    "sorted_op_owners_list = sorted(numpy.unique(sorted_op_owners_list[sorted_op_owners_list!='']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check that the parents metadata list and the owner-parent links list have all the same parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Gas Atacama', 'Delek Group', 'Gas Natural', 'Elmina Copelouzou', 'Avocet LNG', 'Sendai City Gas Bureau', 'OCO Partners', 'POSCO', 'PipeChina', 'DESFA', 'Sakaide LNG', 'EPV Energy', 'Chugoku Electric Power', 'Isramco', 'Petroleum Industry Pension Fund', 'China National Offshore Oil Corporation', 'OMV', 'Dow Chemical', 'Ningbo Power Development Co.', 'Tohoku Electric Power', 'Engro Corporation', 'ENEOS Corporation', 'JSK Group', 'China Suntien Green Energy Corporation Limited', 'China Petrochemical Corporation', 'Tamar Petroleum', 'Geoplin', 'Cott Oil & Gas', 'The National Gas Company of Trinidad and Tobago', 'Republic of Benin', 'Rostec', 'Orca LNG', 'Melbana Energy', 'Zhejiang Energy Group', 'Huainan Mine Group', 'Société Béninoise d’Energie Electrique', 'VGS Group', 'Tamil Nadu Industrial Development Corporation', 'Skulte LNG Terminal', 'All Tech Energy', 'Sirte Oil Company', 'Heibei Natural Gas', 'Pars Energy', 'Fox Petroleum', '3 individual investors', 'Tobu Gas', 'Jiaxing Gas', 'Shizuoka Gas', 'Parallax Enterprises LLC', 'Chevron', 'Snam', 'DEPA', 'Canatxx LNG Limited', 'Beijing Energy International Holding Co', 'Lucion Services', 'Petrobangla', 'Liquefied Natural Gas Limited', 'Saving, Welfare, & Pension Funds of Petroleum Industry', 'Hanwha Investment and Securities', 'TotalEnergies', 'Guangdong Energy Group Natural Gas Co., Ltd', 'Hokuriku Electric', 'Gazprombank', 'BHP Billiton Group', 'Credit Agricole Group', 'Shanghai Jiakun International Trade Co., Ltd.', 'Bulgartransgaz', 'Gas and Heat', 'Guangxi Beibu Bay International Port Group', 'LNG Gorskaya', 'Tianjin Hengrongda Investment Company', 'United LNG', 'China Guodian', 'JupiterMLP', 'Honghua Group', 'Tokyo Electric Power Company', 'Aguadulce LNG', 'Dioriga Gas', 'SCT&E LNG', 'China Energy Reserve and Chemicals Group Company', 'Hangzhou Gas', 'Nordliq', 'CIMC Yonglong Tianijin Fin', 'Kitsault Energy', 'Oaktree Capital Management', 'Energy Transfer Equity', 'Colbún S.A.', 'Government of Brunei', 'Pardus Energy', 'Gastrade', 'Jefferies Financial Group', 'Tidelands Oil & Gas Corp', 'RusGazDobycha', 'Gruppo Falcone', 'Petoro', 'Uniper', 'Occidental Petroleum', 'Exelon Corporation', 'DKRW Energy', 'Tianjin Provisional Government', 'Cangzhou Port Affair Bureau', 'Ministry of Infrastructure and Energy', 'Idemitsu Kosan', 'Huafeng Group', 'Zhuhai Huachang Investment Co', 'Kina Petroleum', 'DEFA', 'Wenzhou Daxiaomen Island Investment Development Corporation', 'Gasol', 'LNG Japan Corporation', 'Saibu Gas', 'XinAo Group Co Ltd', 'PT Perusahaan Gas Negara', 'EIG Global Energy Partners', 'Hengtong Logistics', 'Kinder Morgan', 'Tree Energy Solutions', 'Eilat Ashkelon Pipeline Company', 'Tianjin Hengrongda Technology Company', 'Swedegas', 'Predator Oil & Gas', 'Haytrac Power and Gas', 'Gazprom', 'AECOM Capital', 'Panbil Group', 'Huaihe Energy Holding Group', 'Rockyview Resources', '北京燃气集团', 'Everest Infrastructure Partners', 'PT Japan Indonesia LNG Co (JILCO)', 'Dialog Group', 'Hess Corporation', 'Hokkaido Gas', 'CLP Holdings Ltd', 'EXMAR Group', 'Petrolifera Italo Rumena', 'Gulf Coast LNG', 'Chita LNG', 'ENAP', 'Kestrel Energy Partners', 'Stolt LNGaz', 'Poweo', 'GasLog Cyprus Investments', 'China Overseas Smart City Technology Group Co., Ltd.', 'Sojitz', 'Novatek', 'Samson Oil & Gas Limited', 'Petrel Resources', 'WestPac LNG Corporation', 'Jiangsu Guoxin Investment Group', 'Porto Norte Fluminense S.A.', 'Taipower', 'E.ON', 'Höegh LNG', 'Iranian Gas Exporting Company', 'Epcilon LNG LLC USA', 'RomGaz', 'Axa', 'Höegh LNG', 'Pacific LNG Operations', 'PEMEX', 'SOCAR', 'Atlantic Sea Island Group', 'Partners Group', 'Oita LNG', 'Kogas', 'Tallgrass Energy', 'Japex', 'Okinawa Electric Power', 'Jiangxi Investment Group', 'Santos Limited', 'Chubu Electric Power', 'Northern Star Natural Gas', 'IAHL Corporation', 'Government of Ukraine', 'Petróleos de Venezuela', 'Egyptian Natural Gas Holding Company', 'Guanghui Energy Group', '4Gas', 'Gas Equipment Co., Ltd.', 'Freeport-McMoRan Inc', 'SSAB', 'Pangea LNG', 'China Huadian', 'Oman Oil Company', 'Sempra Energy', 'Great United Petroleum Company', 'Calor', 'Teekay', 'Enbridge', 'Government of Aceh', 'GCL Group', 'AltaGas', 'Galp Group', 'Fan Chuanying', 'InfraStrata', 'Kalla Group', 'Enel', 'LNG Group Panama', 'Schlumberger', 'EgeGaz', 'BOTAŞ', 'Nippon Gas', 'Sorgenia', 'Trencap', 'Zhongtie Gallon LNG Logistics Co., Ltd.', 'Ameris Capital', 'Air Liquide', 'Sabah Energy', 'Alexela', 'Dalian Construction Investment Co.', 'Porto Central Complexo Industrial Portuário S.A.', 'Resources Energy Inc.', 'DEPA Commercial', 'API Holding', 'China Huanqui Contracting and Engineering Corp Reliance', 'Zhejiang Zhongyou Longchang Energy', 'Ningbo Wanguang Investment Management Partnership', 'Government of Colombia', 'Grupo Vale Azul Participações', 'Molgas', 'Samsung', 'Gasum', 'Shenzhen Energy', 'Petronet LNG ', 'Quoddy Bay LNG', 'Government of Estonia', 'Shenergy Group', 'Stewart Energy', 'Government of Timor-Leste', 'Copel', 'SODECO', 'Cassa Depositi e Prestiti', 'Nogaholding', 'Guangdon Yuedian Group', 'Fujian Investment and Development Co', \"Government of Nisga'a Nation\", 'Hidrovias do Brasil S.A.', 'Government of Oman', 'Rosneft', 'China Energy Group Haikong New Energy Co., Ltd', 'Nippon Steel Corporation', 'Shanghai Jiachang Petrochemical Co., Ltd.', 'Imperial Oil Resources', 'Tojeiro Group', 'Perusahaan Gas Negara', 'Corporacion America', 'SUEZ Energy', 'Sumitomo Group', 'Longkou Port', 'Plinacro', 'HEP Grupa', 'Ganzhou Maokang Investment Management Partnership', 'ENN Group', 'Hiroshima Gas', 'Shanghai Garson Petroleum & Chemicals Co., Ltd.', 'Iren Group', 'NextDecade', 'NewTimes Energy', 'Lloyds Energy Group LLC', 'Exmar', 'General Electric Company', 'Macau Natural Gas Company Limited', 'PT Pelindo 3', 'Totisa Holdings', 'Yudean Group', 'Vitol Holding II S.A.', 'PetroSA', 'Brunei National Petroleum', 'Beijing Enterprises', 'Primoris Services Corporation', 'Leif Höegh & Co', 'Strom', 'Sendai Gas', 'Caofeidian Xintian Liquefaction Natural Gas Company', 'Zhongtian Energy', 'Tianjin Gas Group', 'Valener', 'Korea LNG', 'Tesla Resources LLC', 'JGC Corporation', 'Equinor', 'Torp Technology', 'Berry Group', 'Bahrain Petroleum Company', 'GS Group', 'Reliance Industries Limited', 'Dor Gas', 'Haddington Ventures', 'Oil and Natural Gas Corporation Limited', 'Tianjin Port Group', 'Cosan', 'Stolt-Nielsen Limited', 'Innergy Holdings', 'Calais LNG', 'YPF', 'JXTG Holdings', 'SunLNG', 'InterEnergy Holdings', 'Government of Galician', 'Nigerian National Petroleum Corporation', 'Rizhao Port', 'Beijing Enterprises Clean Energy Group Limited', 'Energía del Pacífico', 'Oiltanking', 'Grupo Dislub Equador', 'Caofeidian Financial Holding Group Co., Ltd.', 'Guangzhou Gas Group', 'Latvenergo', 'Sino Gas & Energy Holdings', 'Hubei Minsheng Oil & LNG Co', 'Canadian Superior Energy', 'Global LNG', 'Steelhead LNG', 'CPL Concordia', 'Indian Oil Corporation Limited', 'Government of Johor', 'Sinoenergy', 'Hubei Energy', 'Cheniere Energy', 'GNPower', 'TC Energy', 'Government of Sarawak', 'Pacific Oil & Gas Limited', 'Ningxia Baota Petrohemical Group', 'AGA Gas', 'RasGas', 'Électricité de France', 'Huaying Investment Holding Group', 'Pembina Pipeline Corporation', 'Barca', 'Irving Group of Companies', 'Shenzan Gas', 'Sembcorp', 'CIM Group', 'Itochu Corporation', 'Outokumpu Group', 'MOL Group', 'Government of Gibraltar', 'S.B. Adani Family Trust', 'Jiangsu Yangkou Port Co., Ltd.', 'General America LNG', 'REN Atlantico', 'Yanqiao Group', 'Kitakyushu LNG', 'Phoenix Petroleum', 'Société Nationale des Hydrocarbures', 'Ancala Partners', 'Cutuco Energy', 'Hongkong Shanghai Manjala Power', 'Shanghai Wanpeng International Trade Co', 'Basque Energy Board (EVE)', 'Shenzhen Gas', 'PGNiG', 'Jiufeng Group', 'Tak-Iranian Gas Company', 'Fluxys', 'Siemens', 'Bumi Armada', 'Eneva', 'Servtec Investimentos e Participações', 'Eos', 'Gulf Investment Corporation', 'Mitsubishi UFJ Financial Group', 'National Grid', 'IBK Securities', 'Zhonglian Gallon Enterprise Management Beijing Co., Ltd.', 'Royal Golden Eagle', 'Dalian Port Corporation Limited', 'BG Group', 'Ophir Energy', 'Watson Island LNG Corporation', 'Engie', 'RWE AG', 'Buss Group']\n"
     ]
    }
   ],
   "source": [
    "# check that all parents have parent metadata\n",
    "print(list(set(sorted_parents_list)-set(sorted_owner_parents_list)))\n",
    "print(list(set(sorted_owners_list)-set(sorted_op_owners_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T020701\n",
      "T023201\n",
      "T023202\n",
      "T023203\n",
      "T023701\n",
      "T023702\n",
      "T023703\n",
      "T023704\n",
      "T024801\n",
      "T026301\n",
      "T026302\n",
      "T027700\n",
      "T030201\n",
      "T032500\n",
      "T032601\n",
      "T032602\n",
      "T032603\n",
      "T032604\n",
      "T032801\n",
      "T035201\n",
      "T036500\n",
      "T037600\n",
      "T038600\n",
      "T040000\n",
      "T040001\n",
      "T040200\n",
      "T040600\n",
      "T042300\n",
      "T042800\n",
      "T043600\n",
      "T043800\n",
      "T045900\n",
      "T046100\n",
      "T047200\n",
      "T050300\n",
      "T050401\n",
      "T050402\n",
      "T052300\n",
      "T052900\n",
      "T053800\n",
      "T054000\n",
      "T054900\n",
      "T055001\n",
      "T055200\n",
      "T056700\n",
      "T058801\n",
      "T060800\n",
      "T060900\n",
      "T061901\n",
      "T062401\n",
      "T063300\n",
      "T063700\n",
      "T064101\n",
      "T064102\n",
      "T064103\n",
      "T064600\n",
      "T064800\n",
      "T066101\n",
      "T066102\n",
      "T066103\n",
      "T066104\n",
      "T066105\n",
      "T066300\n",
      "T066800\n",
      "T067301\n",
      "T067302\n",
      "T067303\n",
      "T067304\n",
      "T068300\n",
      "T069600\n",
      "T069800\n",
      "T070501\n",
      "T070600\n",
      "T072100\n",
      "T072200\n",
      "T072400\n",
      "T072701\n",
      "T072801\n",
      "T072802\n",
      "T073300\n",
      "T073400\n",
      "T073700\n",
      "T079200\n",
      "T079800\n",
      "T082500\n",
      "T085700\n",
      "T085900\n",
      "T086100\n",
      "T086500\n",
      "T088000\n",
      "T088200\n",
      "T088500\n",
      "T090700\n",
      "T091701\n",
      "T091702\n",
      "T092400\n",
      "T094200\n",
      "T094700\n",
      "T095000\n",
      "T095400\n",
      "T095500\n",
      "T097000\n",
      "T097500\n",
      "T097900\n",
      "T098000\n",
      "T104201\n",
      "T105400\n",
      "T041301\n",
      "T106000\n",
      "T106500\n",
      "T107000\n",
      "T107100\n",
      "T067300\n",
      "T107200\n",
      "T107201\n",
      "T107202\n",
      "T107203\n",
      "T107204\n",
      "T107205\n",
      "T107206\n",
      "T107207\n",
      "T107208\n",
      "T107209\n",
      "T107210\n",
      "T107211\n"
     ]
    }
   ],
   "source": [
    "# first go through all owners without percents\n",
    "\n",
    "for combo_id in owners_df_existing_nopercs.index:\n",
    "    print(combo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# replace all -- with nans\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m terms_df_orig\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mnumpy\u001b[49m\u001b[38;5;241m.\u001b[39mnan, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# remove oil export terminals\u001b[39;00m\n\u001b[1;32m      4\u001b[0m terms_df_orig \u001b[38;5;241m=\u001b[39m terms_df_orig\u001b[38;5;241m.\u001b[39mloc[terms_df_orig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOil\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "# replace all -- with nans\n",
    "terms_df_orig.replace('--', numpy.nan, inplace=True)\n",
    "# remove oil export terminals\n",
    "terms_df_orig = terms_df_orig.loc[terms_df_orig['Type1']!='Oil']\n",
    "# remove anything without a wiki page\n",
    "terms_df_orig = terms_df_orig.loc[terms_df_orig['Wiki']!='']\n",
    "# remove N/A statuses\n",
    "terms_df_orig = terms_df_orig.loc[terms_df_orig['Status']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '2022_02_18_compiled' created1\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "## VARIABLES ##\n",
    "###############\n",
    "\n",
    "#######################\n",
    "## ALWAYS CHECK THIS ##\n",
    "#######################\n",
    "\n",
    "# Downloaded filename that will be compiled\n",
    "# TODO: change to pygsheets to prevent error of using an old copy\n",
    "dlFile = \"Global Gas Plant Tracker (GGPT) - dl 2022-02-18.xlsx\"\n",
    "\n",
    "# Directory to find the downloaded GGPT copy\n",
    "tmpDir = '/Users/jennymartos/Documents/GEM/GGPT/GGPT copies/'\n",
    "\n",
    "## User Defined ##\n",
    "# Every tab to compile\n",
    "sheets_included = ['Russia', \n",
    "                   'Australia and New Zealand', \n",
    "                   'Africa (sub-Saharan)', \n",
    "                   'China', \n",
    "                   'European Union',  \n",
    "                   'Europe', \n",
    "                   'Latin America', \n",
    "                   'North America', \n",
    "                   'Middle East & North Africa', \n",
    "                   'East Asia', \n",
    "                   'SE Asia', \n",
    "                   'South Asia', \n",
    "                   'Turkey', \n",
    "                   'Central Asia', \n",
    "                   'Western Asia']\n",
    "\n",
    "# The tab where codes and licensing will be written\n",
    "coverSheet = 'About'\n",
    "\n",
    "all_sheets = [] # initialize\n",
    "\n",
    "# Parent Directory path (where you want to locally store outputs on your computer)\n",
    "parent_dir = '/Users/jennymartos/Documents/GEM/GGPT/GGPT-Compile'\n",
    "\n",
    "## Automatic ##\n",
    "# Today's date\n",
    "dateToday = time.strftime(\"%Y_%m_%d\")\n",
    "# New data output directory \n",
    "directory = dateToday+\"_compiled\"\n",
    "\n",
    "# Path \n",
    "dataLoc = os.path.join(parent_dir, directory)\n",
    "\n",
    "## Storing Outputs ##\n",
    "# If folder already exists, increment name\n",
    "i=1\n",
    "while os.path.isdir(dataLoc):\n",
    "    dataLoc = os.path.join(parent_dir, directory+str(i))\n",
    "    i+=1\n",
    "\n",
    "# Create the directory \n",
    "os.mkdir(dataLoc) \n",
    "print(\"Directory '% s' created\" % directory+str(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggpt_xl = pd.ExcelFile(tmpDir + dlFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in sheets_included:   \n",
    "    one_sheet = pd.read_excel(ggpt_xl, sheet_name=sheet, dtype={'Unit name':str, 'WEPP location ID': str})\n",
    "    all_sheets += [one_sheet] # Array of every tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_to_process = pd.concat(all_sheets, sort=False) # concat on an array is fastest merge option\n",
    "gas_to_process = gas_to_process.reset_index(drop=True)\n",
    "gas_to_process = gas_to_process.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in gas_to_process.columns:\n",
    "    if 'Unnamed: ' in col:\n",
    "        gas_to_process = gas_to_process.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_clean_ggpt_ownership(ggpt_xl):\n",
    "    df = pd.read_excel(ggpt_xl, sheet_name='owner-parent')\n",
    "    \n",
    "    df = df.dropna(subset=['Owner'], how='any')\n",
    "\n",
    "    for col in df.columns:\n",
    "        if 'Unnamed: ' in col:\n",
    "            df = df.drop(col, axis=1)\n",
    "        \n",
    "    # exclude empty rows\n",
    "    df = df[df['Owner'].isna()==False]\n",
    "            \n",
    "    ggpt_ownership = df\n",
    "    print(f\"Number of rows after filtering Ownership sheet: {len(df)}\")\n",
    "    \n",
    "    return ggpt_ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering Ownership sheet: 3188\n"
     ]
    }
   ],
   "source": [
    "ggpt_parents = read_and_clean_ggpt_ownership(ggpt_xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up, convert dtypes and values\n",
    "for df in [ggpt_parents]:\n",
    "        for col in df.columns:\n",
    "            df[col] = df[col].replace('', np.nan)\n",
    "\n",
    "for num in range(1,12):\n",
    "    owner_pct_col = f'Owner{num}%'\n",
    "    gas_to_process[owner_pct_col] = gas_to_process[owner_pct_col].astype(str)\n",
    "    gas_to_process[owner_pct_col] = gas_to_process[owner_pct_col].replace('', np.nan).str.replace('%', '').astype(float)\n",
    "for num in range(1,12):\n",
    "    parent_pct_col = f'Parent{num}%'\n",
    "    try:\n",
    "        ggpt_parents[parent_pct_col] = ggpt_parents[parent_pct_col].astype(str)\n",
    "        ggpt_parents[parent_pct_col] = ggpt_parents[parent_pct_col].replace('', np.nan).str.replace('%', '').astype(float)\n",
    "    except:\n",
    "        print(f\"Exception in trying to convert column {parent_pct_col}\")\n",
    "        print(\"All columns in df:\")\n",
    "        print(ggpt_parents.columns.tolist())\n",
    "        print(\"=======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggpt_parents = ggpt_parents.set_index('Owner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condensing Owner and Parent strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_owner_and_parent_strings(gas_to_process, ggpt_parents):\n",
    "    \"\"\"\n",
    "    Works for GOGET & GGPT.\n",
    "    \"\"\"\n",
    "    \n",
    "    for row in gas_to_process.index:\n",
    "        owners_str = '' # initialize\n",
    "        parents_str = '' # initialize\n",
    "        parents_ref_str = '' #initialize\n",
    "\n",
    "        for o_num in range(1, 5+1):            \n",
    "            owner_num = gas_to_process.at[row, f'Owner {o_num}']\n",
    "            owner_num_fract = gas_to_process.at[row, f'Owner {o_num} %']\n",
    "            \n",
    "            # create owners_str\n",
    "            owners_str = create_owners_string_for_row_and_owner_num(\n",
    "                gas_to_process, row, owner_num, owners_str, owner_num_fract)\n",
    "                \n",
    "            # iterative added to parents_str\n",
    "            parent_array = create_parent_string_for_one_owner(\n",
    "                owner_num, owner_num_fract, \n",
    "                ggpt_parents, parents_str, parents_ref_str)\n",
    "            parents_str = parent_array[0]\n",
    "            parents_ref_str = parent_array[1]\n",
    "            \n",
    "        # clean up ending\n",
    "        owners_str = owners_str.strip('; ')\n",
    "        parents_str = parents_str.strip('; ')\n",
    "        \n",
    "        # put into gas_to_process\n",
    "        gas_to_process.at[row, 'Owner'] = owners_str\n",
    "        gas_to_process.at[row, 'Parent'] = parents_str\n",
    "        gas_to_process.at[row, \"Parent [ref]\"] = parents_ref_str\n",
    "        \n",
    "    return gas_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_owners_string_for_row_and_owner_num(\n",
    "    gas_to_process, row, owner_num, owners_str, owner_num_fract):\n",
    "    \n",
    "    if pd.isna(owner_num) or owner_num == '':\n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "        owner_num_pct_str = convert_owner_fract_to_pct(owner_num_fract)     \n",
    "        if owner_num.lower() == 'other':\n",
    "            owner_num = owner_num.lower()\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # fill in owner & owner %\n",
    "        owners_str += f\"{owner_num} [{owner_num_pct_str}]; \"\n",
    "    \n",
    "    return owners_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_string_for_one_owner(\n",
    "    owner_num, owner_num_fract, ggpt_parents, parents_str, parents_ref_str):    \n",
    "    \"\"\" \n",
    "    For each owner, look up parents in sheet ggpt_parents\n",
    "    \"\"\"\n",
    "    \n",
    "    if owner_num in ggpt_parents.index:\n",
    "        for p_num in range(1, 10+1):\n",
    "            parent_num = ggpt_parents.at[owner_num, f'Parent {p_num}']\n",
    "            try:\n",
    "                if pd.isna(parent_num):\n",
    "                    pass\n",
    "                else:\n",
    "                    # get share of owner that parent owns\n",
    "                    parent_num_fract = ggpt_parents.at[owner_num, f'Parent {p_num} %']\n",
    "\n",
    "                    # calculate fractional ownership of the O&G unit for this parent\n",
    "                    parent_num_own_unit_fract = owner_num_fract * parent_num_fract\n",
    "\n",
    "                    parent_num_own_unit_pct = convert_owner_fract_to_pct(parent_num_own_unit_fract)\n",
    "                    parent_str = f\"{parent_num} [{parent_num_own_unit_pct}]; \"\n",
    "\n",
    "                    # add to collection (parents_str)\n",
    "                    parents_str += parent_str\n",
    "                    parents_ref_str = str(ggpt_parents.at[owner_num, 'Owner-Parent [ref]'])\n",
    "                \n",
    "    \n",
    "            except:\n",
    "                print(f\"Problem with parent_num: {parent_num}\")\n",
    "                print(f\"ggpt_parents.at[owner_num, f'Parent {p_num}']: {ggpt_parents.at[owner_num, f'Parent {p_num}']}\")\n",
    "                print()                            \n",
    "\n",
    "    elif pd.isna(owner_num) or owner_num == '':\n",
    "        pass\n",
    "\n",
    "    elif owner_num.lower() == 'other':\n",
    "        parent_num = f'other [{owner_num_fract}]; '\n",
    "\n",
    "    else:\n",
    "        print(\"Error!\" + f\" Owner isn't in ggpt_parents: {owner_num}\")\n",
    "    \n",
    "    parent_array = [parents_str, parents_ref_str]\n",
    "    return parent_array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_owner_fract_to_pct(share_fract):\n",
    "    if pd.isna(share_fract):\n",
    "        share_pct_str = 'unknown %'\n",
    "    elif type(share_fract) == np.float64:\n",
    "        share_pct_str = \"{:.1f}\".format(share_fract*100) + '%'\n",
    "        share_pct_str = share_pct_str.replace('.0%', '%')\n",
    "    else:\n",
    "        print(\"Error!\" + f\" Owner fract was neither nan nor float; share_fract: {share_fract} & its type: {type(share_fract)}\")\n",
    "        share_pct_str = '____' # placeholder\n",
    "\n",
    "    return share_pct_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_to_process = create_owner_and_parent_strings(gas_to_process, ggpt_parents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in the compiled spreadsheet, removing things like \"Researcher\" and \"Notes\"\n",
    "final_cols = ['Wiki URL', 'Country', 'Plant name', 'Plant name (local script)', 'Unit name', 'Fuel', 'Capacity elec. (MW)', \n",
    "              'Status', 'Technology', 'CHP', 'Start year', 'Retired year', 'Planned retire', 'Owner', 'Parent', 'Latitude', \n",
    "              'Longitude', 'Location accuracy', 'Region', 'City', 'Local area (taluk, county)', 'Major area (prefecture, district)', \n",
    "              'Subnational unit (province, state)', 'Other IDs (location)', 'Other IDs (unit)', \n",
    "              'Other plant names', 'Captive [heat, power, both]', 'Captive industry type',\n",
    "              'Captive non-industry use [heat, power, both, none]', 'GEM location ID', 'GEM unit ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_to_process = gas_to_process[final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add wiki URLS\n",
    "for row in gas_to_process.index:\n",
    "    plant_name = str(gas_to_process.at[row,'Plant name']).replace(' ','_').replace('/', '%2F')\n",
    "    if gas_to_process.at[row,'Wiki URL']=='' or pd.isna(gas_to_process.at[row,'Wiki URL']) == True:\n",
    "        wiki_URL = str('https://www.gem.wiki/') + str(plant_name)\n",
    "        gas_to_process.at[row,'Wiki URL'] = wiki_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_to_process = gas_to_process.sort_values(by=['Region', 'Country', 'Plant name', 'Unit name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_to_process = gas_to_process.reindex(columns = final_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February 2022\n"
     ]
    }
   ],
   "source": [
    "# export variables\n",
    "save_timestamp = time.strftime('%Y-%m-%d', time.localtime())\n",
    "monthYear = time.strftime('%B %Y', time.localtime())\n",
    "monthDayYear = time.strftime('%B %d, %Y', time.localtime())\n",
    "print(monthYear)\n",
    "year = time.strftime('%Y', time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write multiple tabs (pip install xlsxwriter)\n",
    "# https://xlsxwriter.readthedocs.io/example_pandas_multiple.html\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(os.path.join(dataLoc, 'Global Gas Plant Tracker (GGPT) completed '+save_timestamp+'.xlsx'), engine='xlsxwriter')\n",
    "\n",
    "# Keep the metadata tab in front of worksheet\n",
    "about_tab = pd.read_excel(os.path.join(tmpDir, dlFile), sheet_name=coverSheet, header=0, na_filter=False)\n",
    "\n",
    "# copyright etc\n",
    "cp = \"This data is licensed by Global Energy Monitor under a Creative Commons Attribution Non-Commercial Share Alike 4.0 International license (CC BY-NC-SA 4.0)\"\n",
    "\n",
    "contact = 'Contact: Jenny Martos, Project Manager, Global Energy Monitor - jenny.martos@globalenergymonitor.org'\n",
    "\n",
    "ref = 'Citation: \"Global Gas Plant Tracker,\" Global Energy Monitor, ' + monthYear\n",
    "\n",
    "title = pd.DataFrame({'Global Gas Plant Tracker':['Global Gas Plant Tracker - ' + monthYear, cp, contact, ref]})\n",
    "\n",
    "about_tab = pd.concat([title, about_tab]).reset_index(drop = True)\n",
    "about_tab.to_excel(writer, sheet_name='About', index=False, header=False)\n",
    "\n",
    "# Add abbreviations\n",
    "abbreviations = pd.read_excel(os.path.join(tmpDir, dlFile), sheet_name='Abbreviations', header=0, na_filter=False)\n",
    "abbreviations = abbreviations[['Column','Abbreviation','Full Name (English)']]\n",
    "abbreviations = abbreviations.rename({'Full Name (English)': 'Definition'}, axis=1)\n",
    "abbreviations.to_excel(writer, sheet_name = 'Abbreviations', index = False)\n",
    "# auto adjust column width\n",
    "for column in abbreviations:\n",
    "    column_width = max(abbreviations[column].astype(str).map(len).max(), len(column))\n",
    "    col_idx = abbreviations.columns.get_loc(column)\n",
    "    writer.sheets['Abbreviations'].set_column(col_idx, col_idx, column_width)\n",
    "    \n",
    "# Add column key tab\n",
    "column_key = pd.read_excel(os.path.join(tmpDir, dlFile), sheet_name='Column key', header=0, na_filter=False)\n",
    "column_key = column_key.loc[column_key['Column Name'].isin(final_cols)]\n",
    "column_key = column_key[['Column Name', 'Definition']]\n",
    "column_key.to_excel(writer, sheet_name = 'Column key', index = False)\n",
    "# auto adjust column width\n",
    "for column in column_key:\n",
    "    column_width = max(column_key[column].astype(str).map(len).max(), len(column))\n",
    "    col_idx = column_key.columns.get_loc(column)\n",
    "    writer.sheets['Column key'].set_column(col_idx, col_idx, column_width)\n",
    "\n",
    "# Add tab of GGPT data\n",
    "gas_to_process.to_excel(writer, sheet_name='Gas Units', index=False)\n",
    "# auto adjust column width\n",
    "for column in gas_to_process:\n",
    "    column_width = max(gas_to_process[column].astype(str).map(len).max(), len(column))\n",
    "    col_idx = gas_to_process.columns.get_loc(column)\n",
    "    writer.sheets['Gas Units'].set_column(col_idx, col_idx, column_width)\n",
    "\n",
    "# Add parent tab of GGPT data\n",
    "# parent_metadata = pd.read_excel(os.path.join(tmpDir, dlFile), sheet_name='parent metadata', header=0, na_filter=False)\n",
    "# parent_metadata.to_excel(writer, sheet_name = 'Parent metadata', index = False)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59914d4cdf2882751604edf3f1dd6385ce640077546f95a91cf3fdd2be269e3e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "59914d4cdf2882751604edf3f1dd6385ce640077546f95a91cf3fdd2be269e3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
