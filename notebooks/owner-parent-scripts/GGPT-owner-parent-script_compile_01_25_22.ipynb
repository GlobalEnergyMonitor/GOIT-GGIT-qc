{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run QC code before compiling\n",
    "* TO DO: Use pygsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pygsheets\n",
    "import time\n",
    "import config\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '2022_02_18_compiled' created1\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "## VARIABLES ##\n",
    "###############\n",
    "\n",
    "#######################\n",
    "## ALWAYS CHECK THIS ##\n",
    "#######################\n",
    "\n",
    "# Downloaded filename that will be compiled\n",
    "# TODO: change to pygsheets to prevent error of using an old copy\n",
    "dlFile = \"Global Gas Plant Tracker (GGPT) - dl 2022-02-18.xlsx\"\n",
    "\n",
    "# Directory to find the downloaded GGPT copy\n",
    "tmpDir = '/Users/jennymartos/Documents/GEM/GGPT/GGPT copies/'\n",
    "\n",
    "## User Defined ##\n",
    "# Every tab to compile\n",
    "sheets_included = ['Russia', \n",
    "                   'Australia and New Zealand', \n",
    "                   'Africa (sub-Saharan)', \n",
    "                   'China', \n",
    "                   'European Union',  \n",
    "                   'Europe', \n",
    "                   'Latin America', \n",
    "                   'North America', \n",
    "                   'Middle East & North Africa', \n",
    "                   'East Asia', \n",
    "                   'SE Asia', \n",
    "                   'South Asia', \n",
    "                   'Turkey', \n",
    "                   'Central Asia', \n",
    "                   'Western Asia']\n",
    "\n",
    "# The tab where codes and licensing will be written\n",
    "coverSheet = 'About'\n",
    "\n",
    "all_sheets = [] # initialize\n",
    "\n",
    "# Parent Directory path (where you want to locally store outputs on your computer)\n",
    "parent_dir = '/Users/jennymartos/Documents/GEM/GGPT/GGPT-Compile'\n",
    "\n",
    "## Automatic ##\n",
    "# Today's date\n",
    "dateToday = time.strftime(\"%Y_%m_%d\")\n",
    "# New data output directory \n",
    "directory = dateToday+\"_compiled\"\n",
    "\n",
    "# Path \n",
    "dataLoc = os.path.join(parent_dir, directory)\n",
    "\n",
    "## Storing Outputs ##\n",
    "# If folder already exists, increment name\n",
    "i=1\n",
    "while os.path.isdir(dataLoc):\n",
    "    dataLoc = os.path.join(parent_dir, directory+str(i))\n",
    "    i+=1\n",
    "\n",
    "# Create the directory \n",
    "os.mkdir(dataLoc) \n",
    "print(\"Directory '% s' created\" % directory+str(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggpt_xl = pd.ExcelFile(tmpDir + dlFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in sheets_included:   \n",
    "    one_sheet = pd.read_excel(ggpt_xl, sheet_name=sheet, dtype={'Unit name':str, 'WEPP location ID': str})\n",
    "    all_sheets += [one_sheet] # Array of every tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_to_process = pd.concat(all_sheets, sort=False) # concat on an array is fastest merge option\n",
    "gas_to_process = gas_to_process.reset_index(drop=True)\n",
    "gas_to_process = gas_to_process.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in gas_to_process.columns:\n",
    "    if 'Unnamed: ' in col:\n",
    "        gas_to_process = gas_to_process.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_clean_ggpt_ownership(ggpt_xl):\n",
    "    df = pd.read_excel(ggpt_xl, sheet_name='owner-parent')\n",
    "    \n",
    "    df = df.dropna(subset=['Owner'], how='any')\n",
    "\n",
    "    for col in df.columns:\n",
    "        if 'Unnamed: ' in col:\n",
    "            df = df.drop(col, axis=1)\n",
    "        \n",
    "    # exclude empty rows\n",
    "    df = df[df['Owner'].isna()==False]\n",
    "            \n",
    "    ggpt_ownership = df\n",
    "    print(f\"Number of rows after filtering Ownership sheet: {len(df)}\")\n",
    "    \n",
    "    return ggpt_ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after filtering Ownership sheet: 3188\n"
     ]
    }
   ],
   "source": [
    "ggpt_parents = read_and_clean_ggpt_ownership(ggpt_xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up, convert dtypes and values\n",
    "for df in [ggpt_parents]:\n",
    "        for col in df.columns:\n",
    "            df[col] = df[col].replace('', np.nan)\n",
    "\n",
    "for num in range(1, 5+1):\n",
    "    owner_pct_col = f'Owner {num} %'\n",
    "    gas_to_process[owner_pct_col] = gas_to_process[owner_pct_col].astype(str)\n",
    "    gas_to_process[owner_pct_col] = gas_to_process[owner_pct_col].replace('', np.nan).str.replace('%', '').astype(float)\n",
    "for num in range(1, 10+1):\n",
    "    parent_pct_col = f'Parent {num} %'\n",
    "    try:\n",
    "        ggpt_parents[parent_pct_col] = ggpt_parents[parent_pct_col].astype(str)\n",
    "        ggpt_parents[parent_pct_col] = ggpt_parents[parent_pct_col].replace('', np.nan).str.replace('%', '').astype(float)\n",
    "    except:\n",
    "        print(f\"Exception in trying to convert column {parent_pct_col}\")\n",
    "        print(\"All columns in df:\")\n",
    "        print(ggpt_parents.columns.tolist())\n",
    "        print(\"=======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggpt_parents = ggpt_parents.set_index('Owner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condensing Owner and Parent strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_owner_and_parent_strings(gas_to_process, ggpt_parents):\n",
    "    \"\"\"\n",
    "    Works for GOGET & GGPT.\n",
    "    \"\"\"\n",
    "    \n",
    "    for row in gas_to_process.index:\n",
    "        owners_str = '' # initialize\n",
    "        parents_str = '' # initialize\n",
    "        parents_ref_str = '' #initialize\n",
    "\n",
    "        for o_num in range(1, 5+1):            \n",
    "            owner_num = gas_to_process.at[row, f'Owner {o_num}']\n",
    "            owner_num_fract = gas_to_process.at[row, f'Owner {o_num} %']\n",
    "            \n",
    "            # create owners_str\n",
    "            owners_str = create_owners_string_for_row_and_owner_num(\n",
    "                gas_to_process, row, owner_num, owners_str, owner_num_fract)\n",
    "                \n",
    "            # iterative added to parents_str\n",
    "            parent_array = create_parent_string_for_one_owner(\n",
    "                owner_num, owner_num_fract, \n",
    "                ggpt_parents, parents_str, parents_ref_str)\n",
    "            parents_str = parent_array[0]\n",
    "            parents_ref_str = parent_array[1]\n",
    "            \n",
    "        # clean up ending\n",
    "        owners_str = owners_str.strip('; ')\n",
    "        parents_str = parents_str.strip('; ')\n",
    "        \n",
    "        # put into gas_to_process\n",
    "        gas_to_process.at[row, 'Owner'] = owners_str\n",
    "        gas_to_process.at[row, 'Parent'] = parents_str\n",
    "        gas_to_process.at[row, \"Parent [ref]\"] = parents_ref_str\n",
    "        \n",
    "    return gas_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_owners_string_for_row_and_owner_num(\n",
    "    gas_to_process, row, owner_num, owners_str, owner_num_fract):\n",
    "    \n",
    "    if pd.isna(owner_num) or owner_num == '':\n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "        owner_num_pct_str = convert_owner_fract_to_pct(owner_num_fract)     \n",
    "        if owner_num.lower() == 'other':\n",
    "            owner_num = owner_num.lower()\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # fill in owner & owner %\n",
    "        owners_str += f\"{owner_num} [{owner_num_pct_str}]; \"\n",
    "    \n",
    "    return owners_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_string_for_one_owner(\n",
    "    owner_num, owner_num_fract, ggpt_parents, parents_str, parents_ref_str):    \n",
    "    \"\"\" \n",
    "    For each owner, look up parents in sheet ggpt_parents\n",
    "    \"\"\"\n",
    "    \n",
    "    if owner_num in ggpt_parents.index:\n",
    "        for p_num in range(1, 10+1):\n",
    "            parent_num = ggpt_parents.at[owner_num, f'Parent {p_num}']\n",
    "            try:\n",
    "                if pd.isna(parent_num):\n",
    "                    pass\n",
    "                else:\n",
    "                    # get share of owner that parent owns\n",
    "                    parent_num_fract = ggpt_parents.at[owner_num, f'Parent {p_num} %']\n",
    "\n",
    "                    # calculate fractional ownership of the O&G unit for this parent\n",
    "                    parent_num_own_unit_fract = owner_num_fract * parent_num_fract\n",
    "\n",
    "                    parent_num_own_unit_pct = convert_owner_fract_to_pct(parent_num_own_unit_fract)\n",
    "                    parent_str = f\"{parent_num} [{parent_num_own_unit_pct}]; \"\n",
    "\n",
    "                    # add to collection (parents_str)\n",
    "                    parents_str += parent_str\n",
    "                    parents_ref_str = str(ggpt_parents.at[owner_num, 'Owner-Parent [ref]'])\n",
    "                \n",
    "    \n",
    "            except:\n",
    "                print(f\"Problem with parent_num: {parent_num}\")\n",
    "                print(f\"ggpt_parents.at[owner_num, f'Parent {p_num}']: {ggpt_parents.at[owner_num, f'Parent {p_num}']}\")\n",
    "                print()                            \n",
    "\n",
    "    elif pd.isna(owner_num) or owner_num == '':\n",
    "        pass\n",
    "\n",
    "    elif owner_num.lower() == 'other':\n",
    "        parent_num = f'other [{owner_num_fract}]; '\n",
    "\n",
    "    else:\n",
    "        print(\"Error!\" + f\" Owner isn't in ggpt_parents: {owner_num}\")\n",
    "    \n",
    "    parent_array = [parents_str, parents_ref_str]\n",
    "    return parent_array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_owner_fract_to_pct(share_fract):\n",
    "    if pd.isna(share_fract):\n",
    "        share_pct_str = 'unknown %'\n",
    "    elif type(share_fract) == np.float64:\n",
    "        share_pct_str = \"{:.1f}\".format(share_fract*100) + '%'\n",
    "        share_pct_str = share_pct_str.replace('.0%', '%')\n",
    "    else:\n",
    "        print(\"Error!\" + f\" Owner fract was neither nan nor float; share_fract: {share_fract} & its type: {type(share_fract)}\")\n",
    "        share_pct_str = '____' # placeholder\n",
    "\n",
    "    return share_pct_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_to_process = create_owner_and_parent_strings(gas_to_process, ggpt_parents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in the compiled spreadsheet, removing things like \"Researcher\" and \"Notes\"\n",
    "final_cols = ['Wiki URL', 'Country', 'Plant name', 'Plant name (local script)', 'Unit name', 'Fuel', 'Capacity elec. (MW)', \n",
    "              'Status', 'Technology', 'CHP', 'Start year', 'Retired year', 'Planned retire', 'Owner', 'Parent', 'Latitude', \n",
    "              'Longitude', 'Location accuracy', 'Region', 'City', 'Local area (taluk, county)', 'Major area (prefecture, district)', \n",
    "              'Subnational unit (province, state)', 'Other IDs (location)', 'Other IDs (unit)', \n",
    "              'Other plant names', 'Captive [heat, power, both]', 'Captive industry type',\n",
    "              'Captive non-industry use [heat, power, both, none]', 'GEM location ID', 'GEM unit ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_to_process = gas_to_process[final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add wiki URLS\n",
    "for row in gas_to_process.index:\n",
    "    plant_name = str(gas_to_process.at[row,'Plant name']).replace(' ','_').replace('/', '%2F')\n",
    "    if gas_to_process.at[row,'Wiki URL']=='' or pd.isna(gas_to_process.at[row,'Wiki URL']) == True:\n",
    "        wiki_URL = str('https://www.gem.wiki/') + str(plant_name)\n",
    "        gas_to_process.at[row,'Wiki URL'] = wiki_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_to_process = gas_to_process.sort_values(by=['Region', 'Country', 'Plant name', 'Unit name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_to_process = gas_to_process.reindex(columns = final_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February 2022\n"
     ]
    }
   ],
   "source": [
    "# export variables\n",
    "save_timestamp = time.strftime('%Y-%m-%d', time.localtime())\n",
    "monthYear = time.strftime('%B %Y', time.localtime())\n",
    "monthDayYear = time.strftime('%B %d, %Y', time.localtime())\n",
    "print(monthYear)\n",
    "year = time.strftime('%Y', time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write multiple tabs (pip install xlsxwriter)\n",
    "# https://xlsxwriter.readthedocs.io/example_pandas_multiple.html\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(os.path.join(dataLoc, 'Global Gas Plant Tracker (GGPT) completed '+save_timestamp+'.xlsx'), engine='xlsxwriter')\n",
    "\n",
    "# Keep the metadata tab in front of worksheet\n",
    "about_tab = pd.read_excel(os.path.join(tmpDir, dlFile), sheet_name=coverSheet, header=0, na_filter=False)\n",
    "\n",
    "# copyright etc\n",
    "cp = \"This data is licensed by Global Energy Monitor under a Creative Commons Attribution Non-Commercial Share Alike 4.0 International license (CC BY-NC-SA 4.0)\"\n",
    "\n",
    "contact = 'Contact: Jenny Martos, Project Manager, Global Energy Monitor - jenny.martos@globalenergymonitor.org'\n",
    "\n",
    "ref = 'Citation: \"Global Gas Plant Tracker,\" Global Energy Monitor, ' + monthYear\n",
    "\n",
    "title = pd.DataFrame({'Global Gas Plant Tracker':['Global Gas Plant Tracker - ' + monthYear, cp, contact, ref]})\n",
    "\n",
    "about_tab = pd.concat([title, about_tab]).reset_index(drop = True)\n",
    "about_tab.to_excel(writer, sheet_name='About', index=False, header=False)\n",
    "\n",
    "# Add abbreviations\n",
    "abbreviations = pd.read_excel(os.path.join(tmpDir, dlFile), sheet_name='Abbreviations', header=0, na_filter=False)\n",
    "abbreviations = abbreviations[['Column','Abbreviation','Full Name (English)']]\n",
    "abbreviations = abbreviations.rename({'Full Name (English)': 'Definition'}, axis=1)\n",
    "abbreviations.to_excel(writer, sheet_name = 'Abbreviations', index = False)\n",
    "# auto adjust column width\n",
    "for column in abbreviations:\n",
    "    column_width = max(abbreviations[column].astype(str).map(len).max(), len(column))\n",
    "    col_idx = abbreviations.columns.get_loc(column)\n",
    "    writer.sheets['Abbreviations'].set_column(col_idx, col_idx, column_width)\n",
    "    \n",
    "# Add column key tab\n",
    "column_key = pd.read_excel(os.path.join(tmpDir, dlFile), sheet_name='Column key', header=0, na_filter=False)\n",
    "column_key = column_key.loc[column_key['Column Name'].isin(final_cols)]\n",
    "column_key = column_key[['Column Name', 'Definition']]\n",
    "column_key.to_excel(writer, sheet_name = 'Column key', index = False)\n",
    "# auto adjust column width\n",
    "for column in column_key:\n",
    "    column_width = max(column_key[column].astype(str).map(len).max(), len(column))\n",
    "    col_idx = column_key.columns.get_loc(column)\n",
    "    writer.sheets['Column key'].set_column(col_idx, col_idx, column_width)\n",
    "\n",
    "# Add tab of GGPT data\n",
    "gas_to_process.to_excel(writer, sheet_name='Gas Units', index=False)\n",
    "# auto adjust column width\n",
    "for column in gas_to_process:\n",
    "    column_width = max(gas_to_process[column].astype(str).map(len).max(), len(column))\n",
    "    col_idx = gas_to_process.columns.get_loc(column)\n",
    "    writer.sheets['Gas Units'].set_column(col_idx, col_idx, column_width)\n",
    "\n",
    "# Add parent tab of GGPT data\n",
    "# parent_metadata = pd.read_excel(os.path.join(tmpDir, dlFile), sheet_name='parent metadata', header=0, na_filter=False)\n",
    "# parent_metadata.to_excel(writer, sheet_name = 'Parent metadata', index = False)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59914d4cdf2882751604edf3f1dd6385ce640077546f95a91cf3fdd2be269e3e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "59914d4cdf2882751604edf3f1dd6385ce640077546f95a91cf3fdd2be269e3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
